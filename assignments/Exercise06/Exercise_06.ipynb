{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e891730",
   "metadata": {},
   "source": [
    "# Data Literacy Exercise 06\n",
    "\n",
    "Machine Learning in Science, University of Tübingen, Winter Semester 2022\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02683420",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce570f5",
   "metadata": {},
   "source": [
    "Permutation testing is a procedure which can be used to test whether there is an association between two random variables $Z$ and $Y$. Given a set of pairs $D={(z_1, y_1), (z_2, y_2), \\ldots, (z_N, y_N)}$, we want to test whether $Z$ and $Y$ are statistically independent or not.\n",
    "\n",
    "Permutation tests can be defined for different test statistics, but for example we can apply it to $T(D) = \\sum_i (z_i-y_i)^2$. The beauty of the permutation test is that there is a very simple way to compute the distribution of the test statistic under the null hypothesis: If $z_i$ and $y_i$ are independent (which they are under $H_o$), then it should not matter whether we compute ($z_i - y_i$) or ($z_i - y_j$) for a $j$ which is drawn (uniformly) at random! One way to implement this is to simply permute the indices of the $y$’s, and to compute $T(D^*)$ on this permuted data set. By repeating this many times for different (uniformly) random permutations, we can thus compute a histogram of the test statistic under the null. Finally, we can then calculate the p-value by checking what fraction of the (permuted) statistic is smaller than the one we observed!\n",
    "\n",
    "As a concrete example, let's apply this to a regression task. In this case, we assume we have some algorithm that computed predictions $z_i$, and we want to see whether these predictions are closer to the targets $y_i$ than one would expect under the null hypothesis, using the test statistic introduced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598be04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e986ef",
   "metadata": {},
   "source": [
    "## Predicting bike rentals from weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54335a3",
   "metadata": {},
   "source": [
    "### 1. Load our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9599b891",
   "metadata": {},
   "source": [
    "We will be using the [Bike Sharing Dataset](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset) from University of Porto to predict the number of rental bikes from the weather (you can download the .csv from Ilias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb54ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv data using the pandas library\n",
    "df = pd.read_csv(\"bikedata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60c55cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the \"temp\" column as our features (X), and the \"cnt\" column for labels (y)\n",
    "X = ...\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854070d",
   "metadata": {},
   "source": [
    "### 2. Splitting into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc636775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67214ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# Split the arrays into training and test sets, using 30% for test\n",
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f7b98",
   "metadata": {},
   "source": [
    "### 3. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f52e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit a linear regression model to the data\n",
    "reg = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63123c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate a vector of predictions\n",
    "y_pred = ...\n",
    "\n",
    "# Calculate the mean squared error (you can use the sklearn method above for this)\n",
    "mse = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134567b4",
   "metadata": {},
   "source": [
    "### 4. Implement permutation testing\n",
    "\n",
    "Permutation testing is a procedure which allows us to measure how likely the observed metric (in this case, the mean squared error) is obtained by chance. In this case, a p-value represents the fraction of random data sets under a certain null hypothesis where the model performed as well as or better than our observed metric (which was obtained on the true labels).\n",
    "\n",
    "Here, our null hypothesis ($H_0$) is that there is no difference between the performance of our trained model and chance (random guessing). To reject this hypothesis, we must create a null distribution, or a set of random (i.e. permuted, or shuffled) data sets. We then calculate our p-value by comparing the error between our observed predictions (calculated above) and the shuffled data (chance level, to be filled in below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d801e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import shuffle\n",
    "\n",
    "perm_scores = []\n",
    "\n",
    "for i in np.arange(0, 1000):\n",
    "    \n",
    "    # Shuffle the labels\n",
    "    ...\n",
    "    \n",
    "    # Calculate the MSE\n",
    "    mse_perm = ...\n",
    "    \n",
    "    # Append the MSE to perm_scores\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6660521",
   "metadata": {},
   "source": [
    "### 5. Plot\n",
    "\n",
    "Plot a histogram of the test statistic under the null hypothesis. Additionally, plot a vertical line for the value of the observed test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1576bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6af6d7f",
   "metadata": {},
   "source": [
    "### 6. Calculate p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa373c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-value\n",
    "# This will reflect the proportion of MSE from our permuted labels which are lower than or equal to the MSE on the true labels\n",
    "p_val = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec55a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda1351e",
   "metadata": {},
   "source": [
    "If you get a p-value of 0, this means that your observed MSE was better than random guessing across all permutations. You would report this by saying that your p-value is less than the minimum, i.e. $p<.001$ (since we do 1000 permutations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b749e615",
   "metadata": {},
   "source": [
    "### 6. Interpret your results\n",
    "\n",
    "What statement can you make based on the p-value you obtained?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb67bbd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d787120",
   "metadata": {},
   "source": [
    "(We note that permutation testing is often presented as a way to test whether there is a difference in distribution between two sets of observations (see e.g. Wasserman 10.5, or the [Wikipedia entry](https://en.wikipedia.org/wiki/Permutation_test). Permutation tests can be used for either the purpose described here or for testing for a difference between groups, and the two are indeed related.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e665e7e",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b0c4df",
   "metadata": {},
   "source": [
    "## Predicting diabetes from a single feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4387144",
   "metadata": {},
   "source": [
    "Similar to what you just did above, we will recreate the pipeline using different data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42f9216",
   "metadata": {},
   "source": [
    "### 1. Making our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c7b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes_X[:, np.newaxis, 0]  # TO BE CHANGED LATER ON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a30b80",
   "metadata": {},
   "source": [
    "### 2. Splitting into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e7b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training/testing sets\n",
    "# In this case we just take the last 20 samples for test\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "diabetes_y_train = diabetes_y[:-20]\n",
    "diabetes_y_test = diabetes_y[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f690e2d",
   "metadata": {},
   "source": [
    "### 3. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47358568",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d22625",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_y_pred = ...\n",
    "mse = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a651e3",
   "metadata": {},
   "source": [
    "### 4. Implement permutation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25988af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_scores = []\n",
    "\n",
    "for i in np.arange(0, 1000):\n",
    "    \n",
    "    # Shuffle the labels\n",
    "    ...\n",
    "    \n",
    "    # Calculate the MSE\n",
    "    mse_perm = ...\n",
    "    \n",
    "    # Append the MSE to perm_scores\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae992cf",
   "metadata": {},
   "source": [
    "### 5. Plot\n",
    "\n",
    "Plot a histogram of the test statistic under the null hypothesis. Additionally, plot a vertical line for the value of the observed test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5578e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e514ea50",
   "metadata": {},
   "source": [
    "### 6. Calculate p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938a399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c83cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5779a549",
   "metadata": {},
   "source": [
    "### 7. Interpret your results\n",
    "\n",
    "What statement can you make based on the p-value you obtained?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7daeab1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5adc5f7c",
   "metadata": {},
   "source": [
    "### 8. Try again with a different feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a852c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "data = datasets.load_diabetes()\n",
    "\n",
    "data['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0effc",
   "metadata": {},
   "source": [
    "In the code above, we can see that the feature we used previously was 'age'. \n",
    "\n",
    "Copy and paste the code from \"Predicting diabetes from a single feature\" into the cell below, then change the \"0\" to a \"2\" (there is a comment in the code indicating where to do this). By making this change, we are using BMI as our feature, instead of age. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7357f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste code below\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
