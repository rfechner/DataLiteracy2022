{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27f1db18",
   "metadata": {},
   "source": [
    "# Predicting daily bikerider count from temperature and weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e38b684-94dd-4bf8-ad43-e60f379e3068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "# import custom functions for data loading, plotting, helpers for model building etc.\n",
    "import sys  \n",
    "sys.path.insert(0, './../modules')\n",
    "import m_data_loading as mdl\n",
    "import m_plotting as mplot\n",
    "import m_helpers\n",
    "import m_check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f766e10",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "We import a dataset that contains the daily number of bike riders at a counting station in Freiburg (channel name: 'FR1 Dreisam / Hindenburgstr.') in 2021 as well as the daily average temperature and a boolean whether a given day is a business day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c3da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting station and time period\n",
    "city_name = 'Stadt Freiburg'\n",
    "counter_site = 'FR1 Dreisam / Otto-Wels-Str.'\n",
    "channel_name = 'FR1 Dreisam / Hindenburgstr.'\n",
    "start_date = datetime.date(2021, 1, 1)\n",
    "end_date = datetime.date(2021, 12, 31)\n",
    "\n",
    "# import data\n",
    "combined_daily_dat = mdl.get_data_for_location(city_name, counter_site, channel_name, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect\n",
    "combined_daily_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d66f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot daily bikerider count by mean day temperature, separate between business days and weekends\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.title(city_name + '\\ncounter site: ' + counter_site + '\\nchannel name: ' + channel_name);\n",
    "mplot.plot_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4871e1fc",
   "metadata": {},
   "source": [
    "## Statistical Analysis: Multiple Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80e57b8c",
   "metadata": {},
   "source": [
    "Independent variables:  \n",
    "$x_1$: daily average temperature [°C]  \n",
    "$x_2$: indicator variable whether day is a business day $\\{0,1\\}$\n",
    "\n",
    "Dependent variable:  \n",
    "$y$: daily bike rider count\n",
    "\n",
    "\n",
    "Multiple linear regression:  \n",
    "\n",
    "$$\\mu = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 x_2$$\n",
    "$$y \\sim \\mathcal{N}(\\mu, \\sigma) $$\n",
    "\n",
    "\n",
    "$\\beta_0$: intercept on non-business days (i.e., bike rider count at $0°C$ on the weekend)  \n",
    "$\\beta_1$: slope on non-business days (weekends)  \n",
    "$\\beta_2$: additional intercept on business days  \n",
    "$\\beta_3$: interaction parameter (additional slope on business days)\n",
    "\n",
    "So:\n",
    "- on weeekends (i.e., $x_2 = 0$): $$\\mu = \\beta_0 + \\beta_1 x_1$$\n",
    "- on business days (i.e., $x_2 = 1$): $$\\mu = (\\beta_0 + \\beta_2) + (\\beta_1 + \\beta_3) x_1$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3797e32",
   "metadata": {},
   "source": [
    "### Gaussian data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf98386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_linear_model_with_normal_data_distrib(prior_config, dat=combined_daily_dat):\n",
    "    '''\n",
    "    Build a linear model with categories \"business-day vs no-business-day\",\n",
    "    using the given parameter values for the prior distributions and a normal\n",
    "    distribution as data distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    prior_config : dict\n",
    "        Dictionary that contains the parameter values of the prior distributions.\n",
    "    dat : pd.DataFrame\n",
    "        Dataframe with columns 'temperature', 'is_busday' and 'rider_count'.\n",
    "        Default: combined_daily_dat\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : pm.Model\n",
    "        Model\n",
    "    idata : arviz.InferenceData\n",
    "        samples from the posterior\n",
    "    '''\n",
    "    # build linear model with categories \"business-day vs no-business-day\"\n",
    "    with pm.Model() as model:\n",
    "\n",
    "        # data\n",
    "        dat_temps = pm.Data('dat_temps', dat[['temperature']])\n",
    "        dat_busday = pm.Data('dat_busday', dat[['is_busday']])\n",
    "        dat_rider_counts = pm.Data('dat_rider_counts', dat[['rider_count']])\n",
    "        \n",
    "        # prior for parameters beta\n",
    "        # idea: same parametrization as in Frequentist analysis above.\n",
    "        if (prior_config['truncate_intercept_prior']): # truncate intercept prior: >= 0.\n",
    "            beta_intercept = pm.TruncatedNormal(\"beta_intercept\", mu=prior_config['mu_intercept_prior'], sigma=prior_config['sigma_intercept_prior'], lower=0, shape=1)\n",
    "        else:\n",
    "            beta_intercept = pm.Normal(\"beta_intercept\", mu=prior_config['mu_intercept_prior'], sigma=prior_config['sigma_intercept_prior'], shape=1)\n",
    "        beta_slope = pm.Normal(\"beta_slope\", mu=prior_config['mu_slope_prior'], sigma=prior_config['sigma_slope_prior'], shape=1)\n",
    "        beta_intercept_business_days = pm.Normal(\"beta_intercept_business_days\", mu=prior_config['mu_intercept_business_days_prior'], sigma=prior_config['sigma_intercept_business_days_prior'], shape=1)\n",
    "        beta_slope_interaction = pm.Normal(\"beta_slope_interaction\", mu=prior_config['mu_slope_interaction_prior'], sigma=prior_config['sigma_slope_interaction_prior'], shape=1)\n",
    "\n",
    "        # prior for two noise distributions: better small\n",
    "        sigma = pm.Exponential(\"sigma\", lam=.01, shape=2)\n",
    "            \n",
    "        # the linear model function\n",
    "        expected = beta_intercept + beta_slope * dat_temps + beta_intercept_business_days * dat_busday + beta_slope_interaction * dat_temps * dat_busday\n",
    "            \n",
    "        # Data and Likelihood: Gaussian noise\n",
    "        noise = sigma[0] * (1 - dat_busday) + sigma[1] * dat_busday\n",
    "        # TODO use pm.TruncatedNormal with lower=0; but makes prediction slow.\n",
    "        obs = pm.Normal(\"observed\",\n",
    "                        mu=expected,\n",
    "                        sigma=noise,\n",
    "                        observed=dat_rider_counts)\n",
    "\n",
    "        # sample from posterior\n",
    "        idata = pm.sample(5000, chains=4, tune=3000, target_accept=0.9, return_inferencedata=True)\n",
    "\n",
    "    return model, idata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e6f13fd",
   "metadata": {},
   "source": [
    "We know:\n",
    "- daily bike count $\\geq 0$ (for \"usual\" temperature range, i.e., -10°C to 30°C, the model should reflect this)\n",
    "- daily bike rider count increases with temperature\n",
    "- people rather cancel/reschedule a recreational bike ride due to weather than their daily commute (known from literature review and personal experience) (TODO nochmal diskutieren, ob wir das als Vorwissen definieren)\n",
    "- Population of Freiburg $\\approx 230.000$.\n",
    "\n",
    "--> Define prior distributions for the model parameters that reflect this prior knowledge."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21372d80",
   "metadata": {},
   "source": [
    "TODO Kommentar: Build model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27626272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build linear model with categories \"business-day vs no-business-day\"\n",
    "linearCategoricalModel_prior_config = m_helpers.create_prior_config_dict(4000, 2000, 300, 300, 0, 2000, -30, 100, True)\n",
    "linearCategoricalModel, linearCategoricalModel_idata, = build_linear_model_with_normal_data_distrib(linearCategoricalModel_prior_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb7a05b9",
   "metadata": {},
   "source": [
    "Prior predictive check: plot what the priors mean / which regression lines are favored/allowed by priors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3b0054",
   "metadata": {},
   "outputs": [],
   "source": [
    "with linearCategoricalModel:\n",
    "    # generate samples from the prior predictive distribution\n",
    "    linearCategoricalModel_prior_checks = pm.sample_prior_predictive(samples=50, random_seed=123)\n",
    "\n",
    "mplot.prior_pred_check(linearCategoricalModel_prior_checks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19e8517f",
   "metadata": {},
   "source": [
    "Show summary, traces, posterior distributions, as well as regression lines sampled from posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d884043",
   "metadata": {},
   "outputs": [],
   "source": [
    "mplot.show_results_linear_fit(linearCategoricalModel_idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a785c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the posterior distribution for beta_slope + beta_slope_interaction,\n",
    "# i.e., the slope parameter on business days\n",
    "beta_slope_post_chains = linearCategoricalModel_idata.posterior['beta_slope'].values\n",
    "beta_slope_interaction_post_chains = linearCategoricalModel_idata.posterior['beta_slope_interaction'].values\n",
    "beta_slope_weekend_chains = beta_slope_post_chains + beta_slope_interaction_post_chains\n",
    "\n",
    "# plot the posterior distribution\n",
    "az.plot_posterior(beta_slope_weekend_chains, hdi_prob=0.95);\n",
    "\n",
    "# display summary\n",
    "az.summary(beta_slope_weekend_chains)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b1a865d",
   "metadata": {},
   "source": [
    "#### Prior sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Kommentar woanders nutzen\n",
    "# build linear model with categories \"business-day vs no-business-day\", using\n",
    "# prior distributions for intercept and slope with positive mu, and a prior\n",
    "# distribution for the interaction that has a negative mu.\n",
    "# We keep the prior distribution for the additional intercept for business days \n",
    "# zero-centered because we don't know enough about Freiburg to decide whether\n",
    "# the counter site as a \"weekend-trip-location\" or a \"commuting-location\".\n",
    "# ---\n",
    "# TODO Maybe try model with bi-modal prior for the additional intercept on\n",
    "# business days because: we know (from personal experience and literature) that\n",
    "# there is a difference between weekend and business day - but (due to lack of\n",
    "# local knowledge about Freiburg) we don't know in which direction.\n",
    "# ---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a91c16bc",
   "metadata": {},
   "source": [
    "##### Alternative model 1: Zero-centered priors\n",
    "\n",
    "Main difference to original model: Use zero-centered priors. Additionally, priors are wider than in original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7540ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build linear model with categories \"business-day vs no-business-day\", using\n",
    "# zero-centered prior distributions\n",
    "alt_prior_config_1 = m_helpers.create_prior_config_dict(0, 4000, 0, 500, 0, 2000, 0, 150)\n",
    "linearCategoricalModel_alt_prior_config_1, linearCategoricalModel_alt_prior_config_1_idata = build_linear_model_with_normal_data_distrib(alt_prior_config_1)\n",
    "\n",
    "# generate samples from the prior predictive distribution\n",
    "with linearCategoricalModel_alt_prior_config_1:\n",
    "    linearCategoricalModel_alt_prior_config_1_prior_checks = pm.sample_prior_predictive(samples=50, random_seed=123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2dacc52",
   "metadata": {},
   "source": [
    "##### Alternative model 2: Zero-centered priors\n",
    "\n",
    "Difference to alternative model 1: Prior distributions are more narrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b62f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build linear model with categories \"business-day vs no-business-day\", using\n",
    "# zero-centered prior distributions\n",
    "alt_prior_config_2 = m_helpers.create_prior_config_dict(0, 1000, 0, 100, 0, 1000, 0, 100)\n",
    "linearCategoricalModel_alt_prior_config_2, linearCategoricalModel_alt_prior_config_2_idata = build_linear_model_with_normal_data_distrib(alt_prior_config_2)\n",
    "\n",
    "# generate samples from the prior predictive distribution\n",
    "with linearCategoricalModel_alt_prior_config_2:\n",
    "    linearCategoricalModel_alt_prior_config_2_prior_checks = pm.sample_prior_predictive(samples=50, random_seed=123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "554e2da7",
   "metadata": {},
   "source": [
    "##### Alternative model 3: Different slope prior\n",
    "\n",
    "Difference to original model: prior for slope parameter is less positive and more narrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0619c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build linear model with categories \"business-day vs no-business-day\"\n",
    "alt_prior_config_3 = m_helpers.create_prior_config_dict(4000, 2000, 100, 100, 0, 2000, -30, 100, True)\n",
    "linearCategoricalModel_alt_prior_config_3, linearCategoricalModel_alt_prior_config_3_idata = build_linear_model_with_normal_data_distrib(alt_prior_config_3)\n",
    "\n",
    "# generate samples from the prior predictive distribution\n",
    "with linearCategoricalModel_alt_prior_config_3:\n",
    "    linearCategoricalModel_alt_prior_config_3_prior_checks = pm.sample_prior_predictive(samples=50, random_seed=123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "840ff324",
   "metadata": {},
   "source": [
    "##### Compare posterior distributions between the models that were built above (using different parameter values for the prior)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbb5786d",
   "metadata": {},
   "source": [
    "Summarize data of the different model instances built above in one list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecbc99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize idata, prior configuration and prior predictive checks of all models\n",
    "# in one list\n",
    "models_dat = [\n",
    "    {'name': 'alternative model 1', 'idata': linearCategoricalModel_alt_prior_config_1_idata, 'prior_config': alt_prior_config_1, 'prior_checks': linearCategoricalModel_alt_prior_config_1_prior_checks},\n",
    "    {'name': 'alternative model 2', 'idata': linearCategoricalModel_alt_prior_config_2_idata, 'prior_config': alt_prior_config_2, 'prior_checks': linearCategoricalModel_alt_prior_config_2_prior_checks},\n",
    "    {'name': 'alternative model 3', 'idata': linearCategoricalModel_alt_prior_config_3_idata, 'prior_config': alt_prior_config_3, 'prior_checks': linearCategoricalModel_alt_prior_config_3_prior_checks},\n",
    "    {'name': 'model', 'idata': linearCategoricalModel_idata, 'prior_config': linearCategoricalModel_prior_config, 'prior_checks': linearCategoricalModel_prior_checks}\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5474edd9",
   "metadata": {},
   "source": [
    "Compare prior predictive checks: Plot what the priors mean / which regression lines are favored/allowed by priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba1d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices of the models for which to plot the prior predictive checks\n",
    "model_indices = [0,1,2,3]\n",
    "\n",
    "# initialize figure\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "for idx, model_idx in enumerate(model_indices):\n",
    "    plt.subplot(1, len(model_indices), idx+1)\n",
    "    mplot.prior_pred_check(models_dat[model_idx]['prior_checks'], title='Prior predictive checks for ' + models_dat[model_idx]['name'])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc48eed1",
   "metadata": {},
   "source": [
    "Compare MAP and example credible regression lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d3d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices of the models for which to plot the MAP and example posteriors\n",
    "model_indices = [0,1,2,3]\n",
    "\n",
    "# initialize figure\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "for idx, model_idx in enumerate(model_indices):\n",
    "    plt.subplot(1, len(model_indices), idx+1)\n",
    "    mplot.show_data_MAP_and_posts(models_dat[model_idx]['idata'], mplot.plot_linear_fit)\n",
    "    plt.title('MAP and example posteriors for ' + models_dat[model_idx]['name'])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee220cc1",
   "metadata": {},
   "source": [
    "Compare posterior distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25874e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot posterior distributions\n",
    "# compare posterior distributions between the models that were built above\n",
    "# (using different parameter values for the prior)\n",
    "mplot.plot_posteriors(models_dat, [0, 1, 2, 3], var_names=['beta_intercept', 'beta_slope', 'beta_intercept_business_days', 'beta_slope_interaction'], plot_hdi=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9918d811",
   "metadata": {},
   "source": [
    "--> All of the prior parameter values tested above yield roughly the same posterior distributions for the parameters of the regression lines."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8931091",
   "metadata": {},
   "source": [
    "Compare prior and posterior distributions for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae061e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_name in ['beta_intercept', 'beta_slope', 'beta_intercept_business_days', 'beta_slope_interaction']:\n",
    "    mplot.compare_models_priors_and_posteriors(models_dat, [0, 1, 2, 3], var_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de6a91b5",
   "metadata": {},
   "source": [
    "#### Posterior predictive check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9809677",
   "metadata": {},
   "source": [
    "TODO check model assumptions: independence, linear relationship, equal variance/normal distribution, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ff999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linCatMod_ppc, linCatMod_posterior_predicitive_means, linCatMod_errors, linCatMod_median_absolute_error, linCatMod_scaled_MAE, linCatMod_quants_per_datapoint_df, linCatMod_percent_within_50, linCatMod_percent_within_95 = m_check.post_pred_check(linearCategoricalModel, linearCategoricalModel_idata, print_output=True, plot_pred_ints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot prediction intervals together with original datapoints\n",
    "# TODO später entfernen\n",
    "\n",
    "# extract predicted bike rider counts (for business days and non-business days)\n",
    "preds = linCatMod_ppc['observed'][:,:,0]\n",
    "preds_busdays = preds[:, combined_daily_dat[combined_daily_dat['is_busday']].index]\n",
    "preds_nonbusdays = preds[:, combined_daily_dat[~combined_daily_dat['is_busday']].index]\n",
    "\n",
    "# extract temperatures of datapoints (for business days and non-business days)\n",
    "temps_busdays = combined_daily_dat[combined_daily_dat['is_busday']]['temperature']\n",
    "temps_nonbusdays = combined_daily_dat[~combined_daily_dat['is_busday']]['temperature']\n",
    "\n",
    "print('preds shape: ', np.shape(preds))\n",
    "print('busday preds shape: ', np.shape(preds_busdays))\n",
    "print('nonbusday preds shape: ', np.shape(preds_nonbusdays))\n",
    "print('busday temps shape: ', np.shape(temps_busdays))\n",
    "print('nonbusday temps shape: ', np.shape(temps_nonbusdays))\n",
    "\n",
    "# plot\n",
    "az.plot_hdi(temps_busdays, preds_busdays, color='orange') # TODO label: 'HDI...'\n",
    "az.plot_hdi(temps_nonbusdays, preds_nonbusdays, color='blue')\n",
    "mplot.plot_data();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bc2b188",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "Im Großen und ganzen passt das, oder?\n",
    "Zum Beispiel:\n",
    "- variability in Originaldaten ungefähr wie variability in Vorhersagen.\n",
    "- General positive trend in original and predicted data\n",
    "\n",
    "Dass etwa 95% der Original-Datenpunkte im 95% Vorhersageintervall liegen, spricht dafür, dass das Modell passt, oder?\n",
    "\n",
    "Wobei etwa um 5-10°C \"Ausschlag nach unten\" nicht vorhergesagt wird..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53522a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to MAE if we would always predict overall mean:\n",
    "print('Median absolute error when predicting mean: ', np.median(np.abs(combined_daily_dat['rider_count'] - np.mean(combined_daily_dat['rider_count']))))\n",
    "print('standard deviations of absolute errors when predicting mean:', np.std(np.abs(combined_daily_dat['rider_count'] - np.mean(combined_daily_dat['rider_count']))))\n",
    "print('standard deviations of errors:', np.std(combined_daily_dat['rider_count'] - np.mean(combined_daily_dat['rider_count'])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29d387f9",
   "metadata": {},
   "source": [
    "TODO sind densities (siehe unten) anschaulich oder lieber regression lines mit prediction intervals (siehe oben)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f8708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare simulated and original data\n",
    "def compare_sim_to_original(sims, original, xlabel):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    sims : TODO\n",
    "        simulated bike rider counts\n",
    "    original : TODO\n",
    "        original (observed) bike rider counts\n",
    "    xlabel : str\n",
    "        x-axis label\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (plot)\n",
    "    '''\n",
    "    # initialize figure\n",
    "    plt.figure()\n",
    "\n",
    "    # simulated bike rider counts data\n",
    "    for i in np.arange(50):\n",
    "        if i==0: # with label\n",
    "            az.plot_kde(sims[i,:], label='simulated', plot_kwargs={'color': 'grey'})\n",
    "        else:\n",
    "            az.plot_kde(sims[i,:], plot_kwargs={'color': 'grey'})\n",
    "\n",
    "    # original bike rider counts data\n",
    "    az.plot_kde(original, label='original', plot_kwargs={'color': 'red'})\n",
    "\n",
    "    # add axis label and legend\n",
    "    plt.xlabel('Daily number of bike riders')\n",
    "    plt.legend();\n",
    "\n",
    "compare_sim_to_original(preds, combined_daily_dat['rider_count'], 'Daily number of bike riders')\n",
    "\n",
    "# seperated for business days and non-business days\n",
    "compare_sim_to_original(preds_busdays, combined_daily_dat[combined_daily_dat['is_busday']]['rider_count'], 'Daily number of bike riders on business days')\n",
    "compare_sim_to_original(preds_nonbusdays, combined_daily_dat[~combined_daily_dat['is_busday']]['rider_count'], 'Daily number of bike riders on non-business days')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c84ff303",
   "metadata": {},
   "source": [
    "#### Cross validation\n",
    "\n",
    "Check the model's predictive accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bb4d663",
   "metadata": {},
   "source": [
    "TODO random seeds setzen? Für pm.sample_posterior_predictive..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bbf9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO adjust prior config\n",
    "linearCategoricalModel_CV_MAEs, linearCategoricalModel_CV_scaledMAEs, linearCategoricalModel_CV_percent_within_50, linearCategoricalModel_CV_percent_within_95 = m_check.cross_validation(build_linear_model_with_normal_data_distrib, linearCategoricalModel_prior_config, num_folds=5, dat=combined_daily_dat, print_results=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83590289",
   "metadata": {},
   "source": [
    "TODO 95% coverage of 95% prediction interval ist gut, oder? Betrachte neue Daten....\n",
    "\n",
    "TODO Vergleiche mit weiter oben, wo MAE, prediction interval coverage, ... für den ganzen Datensatz, auf dem trainiert wurde, berechnet wurden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9b93cbe",
   "metadata": {},
   "source": [
    "TODO run the same cross validation with poisson. Compare to model with normal distribution (above).\n",
    "Or maybe use az.loo oder arviz.compare?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f99f0b7a",
   "metadata": {},
   "source": [
    "#### Test for new data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bec77cf",
   "metadata": {},
   "source": [
    "##### Test for same counting station, next year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdeeff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify counting station and time period\n",
    "city_name = 'Stadt Freiburg'\n",
    "counter_site = 'FR1 Dreisam / Otto-Wels-Str.'\n",
    "channel_name = 'FR1 Dreisam / Hindenburgstr.'\n",
    "test_start_date = datetime.date(2022, 1, 1)\n",
    "test_end_date = datetime.date(2022, 12, 31)\n",
    "\n",
    "# import data for counting station\n",
    "test_data_next_year = mdl.get_data_for_location(city_name, counter_site, channel_name, test_start_date, test_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data import\n",
    "test_data_next_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af24d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model on data of next year\n",
    "# compare the posterior predictive means with observed (test) data points\n",
    "linCatMod_ppc_next_year, linCatMod_posterior_predicitive_means_next_year, linCatMod_errors_next_year, linCatMod_median_absolute_error_next_year, linCatMod_scaled_MAE_next_year, linCatMod_quants_per_datapoint_df_next_year, linCatMod_percent_within_50_next_year, linCatMod_percent_within_95_next_year = m_check.post_pred_check(linearCategoricalModel, linearCategoricalModel_idata, given_data = test_data_next_year, change_dat=True, print_output=True, plot_error_hist=True, plot_pred_ints=True, plot_post_pred_means=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bc1d63a",
   "metadata": {},
   "source": [
    "TODO for business days: predicted values too small\n",
    "\n",
    "TODO possible reason: Covid + city with university. In 2022, students are back in town."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a0b2bb5",
   "metadata": {},
   "source": [
    "##### Test for another counter site in same city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb7e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify counting station and time period\n",
    "test_city_name = 'Stadt Freiburg'\n",
    "test_counter_site = 'FR2 Güterbahn / Ferd.-Weiß-Str.'\n",
    "test_channel_name = 'FR2 Güterbahn / Ferd.-Weiß-Str.'\n",
    "start_date = datetime.date(2021, 1, 1)\n",
    "end_date = datetime.date(2021, 12, 31)\n",
    "#test_channel_ID = 101014511\n",
    "# TODO use channel_id for identification --> to be able to do so: export also channel_id when building the dataset\n",
    "\n",
    "# extract data for counting station\n",
    "test_data_new_counter_site = mdl.get_data_for_location(test_city_name, test_counter_site, test_channel_name, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475e148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data import\n",
    "test_data_new_counter_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103268ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model on data of another (new) counter site\n",
    "# compare the posterior predictive means with observed (test) data points\n",
    "linCatMod_ppc_new_counter_site, linCatMod_posterior_predicitive_means_new_counter_site, linCatMod_errors_new_counter_site, linCatMod_median_absolute_error_new_counter_site, linCatMod_scaled_MAE_new_counter_site, linCatMod_quants_per_datapoint_df_new_counter_site, linCatMod_percent_within_50_new_counter_site, linCatMod_percent_within_95_new_counter_site = m_check.post_pred_check(linearCategoricalModel, linearCategoricalModel_idata, given_data = test_data_new_counter_site, change_dat=True, print_output=True, plot_error_hist=True, plot_pred_ints=True, plot_post_pred_means=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "995801df",
   "metadata": {},
   "source": [
    "TODO better for another counter site in the same city in the same year than for same counter site in the next year\n",
    "TODO possible reason: Covid, Freiburg ist Uni-Stadt --> more bike riders in 2022 because students are back in town"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE when predicting mean:', np.median(np.abs(test_data_new_counter_site['rider_count'] - np.mean(test_data_new_counter_site['rider_count']))))\n",
    "print('Standard deviation of absolute errors when predicting mean:', np.std(np.abs(test_data_new_counter_site['rider_count'] - np.mean(test_data_new_counter_site['rider_count']))))\n",
    "# TODO 890 vs. 842 --> Heißt das, MAE unseres Modells kaum (numerisch) besser als einfach Mittelwert der Daten vorhersagen? (an neuer counting station)?\n",
    "# TODO und Streuung wäre auch noch kleiner?\n",
    "# TODO Vergleiche mit Modell, das extra für diesen Standort gefittet wurde. Das sollte dann schon deutlich besser sein als einfach nur Mittelwert vorhersagen, oder?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbd08301",
   "metadata": {},
   "source": [
    "##### Test for another city"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72f5c964",
   "metadata": {},
   "source": [
    "TODO search for city for which data for whole 2021 is given and a counting station where there is a 1-to-1-mapping between channel name and channel ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fd18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify counting station and time period\n",
    "test_city_name = 'Stadt Ludwigsburg'\n",
    "test_counter_site = 'Solitudeallee'\n",
    "test_channel_name = 'Solitudeallee Stadteinwärts'\n",
    "start_date = datetime.date(2021, 1, 1)\n",
    "end_date = datetime.date(2021, 12, 31)\n",
    "#test_channel_ID = 101014511\n",
    "# TODO use channel_id for identification --> to be able to do so: export also channel_id when building the dataset\n",
    "\n",
    "# extract data for counting station\n",
    "test_data_new_city = mdl.get_data_for_location(test_city_name, test_counter_site, test_channel_name, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede03a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data import\n",
    "test_data_new_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model on data of another city\n",
    "# compare the posterior predictive means with observed (test) data points\n",
    "linCatMod_ppc_new_city, linCatMod_posterior_predicitive_means_new_city, linCatMod_errors_new_city, linCatMod_median_absolute_error_new_city, linCatMod_scaled_MAE_new_city, linCatMod_quants_per_datapoint_df_new_city, linCatMod_percent_within_50_new_city, linCatMod_percent_within_95_new_city = m_check.post_pred_check(linearCategoricalModel, linearCategoricalModel_idata, given_data = test_data_new_city, change_dat=True, print_output=True, plot_error_hist=True, plot_pred_ints=True, plot_post_pred_means=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6deed8e",
   "metadata": {},
   "source": [
    "TODO scaling passt gar nicht."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "089e6706",
   "metadata": {},
   "source": [
    "#### Fit and test model for normalized rider counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723a6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use different normalization?\n",
    "# TODO heißt das \"normalize\"? \"standardize\"?\n",
    "# TODO standardize? Wie heißt das, wenn Ergebnis in [0, 1]?\n",
    "def normalize_rider_count(dat):\n",
    "    '''\n",
    "    Normalize the rider counts to [0,1].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dat : pd.DataFrame\n",
    "        pandas Dataframe with columns 'temperature', 'is_busday', 'rider_count'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "    '''\n",
    "    dat_normalized_rider_counts = dat.copy()\n",
    "    dat_normalized_rider_counts['rider_count'] = (dat_normalized_rider_counts['rider_count'] - min(dat_normalized_rider_counts['rider_count'])) / (max(dat_normalized_rider_counts['rider_count']) - min(dat_normalized_rider_counts['rider_count']))\n",
    "\n",
    "    return dat_normalized_rider_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b526f29d",
   "metadata": {},
   "source": [
    "##### Build model for normalized rider counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b50a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize rider counts\n",
    "dat_normalized_rider_counts = normalize_rider_count(combined_daily_dat)\n",
    "\n",
    "# build linear model with categories \"business-day vs no-business-day\"\n",
    "prior_config_normalized = m_helpers.create_prior_config_dict(0, 1, 0, 1, 0, 1, 0, 1) # TODO adjust prior\n",
    "linearCategoricalModelForNormalized, linearCategoricalModelForNormalized_idata = build_linear_model_with_normal_data_distrib(prior_config_normalized, dat=dat_normalized_rider_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d223530",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_check.post_pred_check(linearCategoricalModelForNormalized, linearCategoricalModelForNormalized_idata, given_data = dat_normalized_rider_counts, print_output=True, plot_error_hist=True, plot_pred_ints=True, plot_post_pred_means=True);\n",
    "# TODO adjust y-axis label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae3d5bbe",
   "metadata": {},
   "source": [
    "##### Test model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a2bde91",
   "metadata": {},
   "source": [
    "###### Test model on normalized data for new counter site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1659ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "test_data_new_counter_site_normalized = normalize_rider_count(test_data_new_counter_site)\n",
    "\n",
    "# test model on new data\n",
    "linCatModForNormalized_ppc_new_counter_site, linCatModForNormalized_posterior_predicitive_means_new_counter_site, linCatModForNormalized_errors_new_counter_site, linCatModForNormalized_median_absolute_error_new_counter_site, linCatModForNormalized_scaled_MAE_new_counter_site, linCatModForNormalized_quants_per_datapoint_df_new_counter_site, linCatModForNormalized_percent_within_50_new_counter_site, linCatModForNormalized_percent_within_95_new_counter_site = m_check.post_pred_check(linearCategoricalModelForNormalized, linearCategoricalModelForNormalized_idata, given_data = test_data_new_counter_site_normalized, change_dat=True, print_output=True, plot_error_hist=True, plot_pred_ints=True, plot_post_pred_means=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5789d370",
   "metadata": {},
   "source": [
    "Plot prediction intervals and data for original data and normalized data side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bb4897",
   "metadata": {},
   "outputs": [],
   "source": [
    "mplot.plot_data_with_pred_intervals(linCatMod_quants_per_datapoint_df_new_counter_site, dat=test_data_new_counter_site)\n",
    "mplot.plot_data_with_pred_intervals(linCatModForNormalized_quants_per_datapoint_df_new_counter_site, dat=test_data_new_counter_site_normalized, ylabel='Normalized daily number of bike riders')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fe9412c",
   "metadata": {},
   "source": [
    "###### Test model on normalized data for new city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2660ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "test_data_new_city_normalized = normalize_rider_count(test_data_new_city)\n",
    "\n",
    "# test model on new data\n",
    "linCatModForNormalized_ppc_new_city, linCatModForNormalized_posterior_predicitive_means_new_city, linCatModForNormalized_errors_new_city, linCatModForNormalized_median_absolute_error_new_city, linCatModForNormalized_scaled_MAE_new_city, linCatModForNormalized_quants_per_datapoint_df_new_city, linCatModForNormalized_percent_within_50_new_city, linCatModForNormalized_percent_within_95_new_city = m_check.post_pred_check(linearCategoricalModelForNormalized, linearCategoricalModelForNormalized_idata, given_data = test_data_new_city_normalized, change_dat=True, print_output=True, plot_error_hist=True, plot_pred_ints=True, plot_post_pred_means=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a568bb42",
   "metadata": {},
   "source": [
    "Plot prediction intervals and data for original data and normalized data side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260cd688",
   "metadata": {},
   "outputs": [],
   "source": [
    "mplot.plot_data_with_pred_intervals(linCatMod_quants_per_datapoint_df_new_city, dat=test_data_new_city)\n",
    "mplot.plot_data_with_pred_intervals(linCatModForNormalized_quants_per_datapoint_df_new_city, dat=test_data_new_city_normalized, ylabel='Normalized daily number of bike riders')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e44d1c8",
   "metadata": {},
   "source": [
    "### Poisson Regression: Poisson model with identity link function\n",
    "\n",
    "TODO  \n",
    "Reasonable? Might be that lambda-parameter-value of Poisson distribution is <0...  (--> we assume that this is not an issue for our \"region of interest\" (i.e., from -5°C to 25°C))  \n",
    "Poisson-Verteilung der Bike-Rider-Counts? Der Residuen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50612aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_linear_model_with_poisson_data_distrib(prior_config, dat=combined_daily_dat):\n",
    "    '''\n",
    "    Build a linear model with categories \"business-day vs no-business-day\",\n",
    "    using the given parameter values for the prior distributions and a Poisson\n",
    "    distribution as data distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    prior_config : dict\n",
    "        Dictionary that contains the parameter values of the prior distributions.\n",
    "    dat : pd.DataFrame\n",
    "        Dataframe with columns 'temperature', 'is_busday' and 'rider_count'.\n",
    "        Default: combined_daily_dat\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : pm.Model\n",
    "        Model\n",
    "    idata : arviz.InferenceData\n",
    "        samples from the posterior\n",
    "    '''\n",
    "    # build linear poisson (TODO wie heißt das jetzt?) model with categories \"business-day vs no-business-day\"\n",
    "    with pm.Model() as model:\n",
    "\n",
    "        # data\n",
    "        dat_temps = pm.Data('dat_temps', dat[['temperature']])\n",
    "        dat_busday = pm.Data('dat_busday', dat[['is_busday']])\n",
    "        dat_rider_counts = pm.Data('dat_rider_counts', dat[['rider_count']])\n",
    "        \n",
    "        # prior for parameters beta\n",
    "        # idea: same parametrization as in Frequentist analysis above.\n",
    "        if (prior_config['truncate_intercept_prior']): # truncate intercept prior: >= 0.\n",
    "            beta_intercept = pm.TruncatedNormal(\"beta_intercept\", mu=prior_config['mu_intercept_prior'], sigma=prior_config['sigma_intercept_prior'], lower=0, shape=1)\n",
    "        else:\n",
    "            beta_intercept = pm.Normal(\"beta_intercept\", mu=prior_config['mu_intercept_prior'], sigma=prior_config['sigma_intercept_prior'], shape=1)\n",
    "        beta_slope = pm.Normal(\"beta_slope\", mu=prior_config['mu_slope_prior'], sigma=prior_config['sigma_slope_prior'], shape=1)\n",
    "        beta_intercept_business_days = pm.Normal(\"beta_intercept_business_days\", mu=prior_config['mu_intercept_business_days_prior'], sigma=prior_config['sigma_intercept_business_days_prior'], shape=1)\n",
    "        beta_slope_interaction = pm.Normal(\"beta_slope_interaction\", mu=prior_config['mu_slope_interaction_prior'], sigma=prior_config['sigma_slope_interaction_prior'], shape=1)\n",
    "            \n",
    "        # the linear model function\n",
    "        expected = beta_intercept + beta_slope * dat_temps + beta_intercept_business_days * dat_busday + beta_slope_interaction * dat_temps * dat_busday\n",
    "        # TODO hier vielleicht noch sicherstellen, dass es >= 0 ist? Für Poisson...\n",
    "\n",
    "        # Poisson likelihood\n",
    "        obs = pm.Poisson(\"observed\",\n",
    "                        mu=expected,\n",
    "                        observed=dat_rider_counts)\n",
    "\n",
    "        # sample from posterior\n",
    "        idata = pm.sample(2000, chains=4, tune=3000, target_accept=0.9, return_inferencedata=True)\n",
    "\n",
    "    return model, idata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d312056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior for parameter vector beta\n",
    "prior_config_poisson = m_helpers.create_prior_config_dict(4000, 2000, 300, 300, 0, 2000, -30, 100)\n",
    "linearPoissonModel, linearPoissonModel_idata = build_linear_model_with_poisson_data_distrib(prior_config_poisson, dat=combined_daily_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00353c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print / plot the fit results\n",
    "mplot.show_results_linear_fit(linearPoissonModel_idata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "680f6b41",
   "metadata": {},
   "source": [
    "--> TODO interaction ist hier signifikant. Liegt das an prior?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c56d803f",
   "metadata": {},
   "source": [
    "##### Posterior predictive check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab429f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior predictive check\n",
    "m_check.post_pred_check(linearPoissonModel, linearPoissonModel_idata, print_output=True, plot_pred_ints=True, plot_post_pred_means=False, quant0=True);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "368acdf3",
   "metadata": {},
   "source": [
    "TODO --> coverage ist miserabel. Model passt vermutlich nicht."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d87da6e",
   "metadata": {},
   "source": [
    "TODO prediction viel zu wenig Varianz, oder? Data overdispersed?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82eb04cb",
   "metadata": {},
   "source": [
    "### Negative Binomial Regression: Negative binomial model with identity link function\n",
    "\n",
    "TODO Since data seems overdispersed (for Poisson), try it with negative binomial distribution as data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df69b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_linear_model_with_negative_binomial_data_distrib(prior_config, dat=combined_daily_dat):\n",
    "    '''\n",
    "    Build a linear model with categories \"business-day vs no-business-day\",\n",
    "    using the given parameter values for the prior distributions and a Negative\n",
    "    Binomial distribution as data distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    prior_config : dict\n",
    "        Dictionary that contains the parameter values of the prior distributions.\n",
    "    dat : pd.DataFrame\n",
    "        Dataframe with columns 'temperature', 'is_busday' and 'rider_count'.\n",
    "        Default: combined_daily_dat\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : pm.Model\n",
    "        Model\n",
    "    idata : arviz.InferenceData\n",
    "        samples from the posterior\n",
    "    '''\n",
    "    # build linear negative binomial (TODO wie heißt das jetzt?) model with categories \"business-day vs no-business-day\"\n",
    "    with pm.Model() as model:\n",
    "\n",
    "        # data\n",
    "        dat_temps = pm.Data('dat_temps', dat[['temperature']])\n",
    "        dat_busday = pm.Data('dat_busday', dat[['is_busday']])\n",
    "        dat_rider_counts = pm.Data('dat_rider_counts', dat[['rider_count']])\n",
    "        \n",
    "        # prior for parameters beta\n",
    "        # idea: same parametrization as in Frequentist analysis above.\n",
    "        if (prior_config['truncate_intercept_prior']): # truncate intercept prior: >= 0.\n",
    "            beta_intercept = pm.TruncatedNormal(\"beta_intercept\", mu=prior_config['mu_intercept_prior'], sigma=prior_config['sigma_intercept_prior'], lower=0, shape=1)\n",
    "        else:\n",
    "            beta_intercept = pm.Normal(\"beta_intercept\", mu=prior_config['mu_intercept_prior'], sigma=prior_config['sigma_intercept_prior'], shape=1)\n",
    "        beta_slope = pm.Normal(\"beta_slope\", mu=prior_config['mu_slope_prior'], sigma=prior_config['sigma_slope_prior'], shape=1)\n",
    "        beta_intercept_business_days = pm.Normal(\"beta_intercept_business_days\", mu=prior_config['mu_intercept_business_days_prior'], sigma=prior_config['sigma_intercept_business_days_prior'], shape=1)\n",
    "        beta_slope_interaction = pm.Normal(\"beta_slope_interaction\", mu=prior_config['mu_slope_interaction_prior'], sigma=prior_config['sigma_slope_interaction_prior'], shape=1)\n",
    "            \n",
    "        # the linear model function\n",
    "        expected = beta_intercept + beta_slope * dat_temps + beta_intercept_business_days * dat_busday + beta_slope_interaction * dat_temps * dat_busday\n",
    "\n",
    "        # Negative binomial likelihood\n",
    "        alphas = pm.HalfNormal(\"alpha\", 4, shape=2)\n",
    "        alpha = alphas[0] * (1 - dat_busday) + alphas[1] * dat_busday\n",
    "        obs = pm.NegativeBinomial(\"observed\",\n",
    "                        mu=expected, # TODO does this make sense?\n",
    "                        alpha=alpha,\n",
    "                        observed=dat_rider_counts)\n",
    "\n",
    "        # sample from posterior\n",
    "        idata = pm.sample(2000, chains=4, tune=3000, target_accept=0.9, return_inferencedata=True)\n",
    "\n",
    "    return model, idata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c1835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and fit model\n",
    "prior_config_neg_binom = m_helpers.create_prior_config_dict(4000, 2000, 300, 300, 0, 2000, -30, 100)\n",
    "linearNegBinomModel, linearNegBinomModel_idata = build_linear_model_with_negative_binomial_data_distrib(prior_config_neg_binom, dat=combined_daily_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print / plot the fit results\n",
    "mplot.show_results_linear_fit(linearNegBinomModel_idata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fd6a1f4",
   "metadata": {},
   "source": [
    "--> TODO Interaction ist hier signifikant. Liegt das an prior? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39e555a6",
   "metadata": {},
   "source": [
    "##### Posterior predictive check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693651cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior predictive check\n",
    "m_check.post_pred_check(linearNegBinomModel, linearNegBinomModel_idata, print_output=True, plot_pred_ints=True, plot_post_pred_means=False, quant0=True);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ee66d3a",
   "metadata": {},
   "source": [
    "--> Much better than using Poisson data distribution. But still the issue: Negative binomial... variance increses with mean - which does not seem to be the case in the training data.\n",
    "\n",
    "TODO beschreiben"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71cebb7d",
   "metadata": {},
   "source": [
    "---\n",
    "TODO  \n",
    "Notes:\n",
    "\n",
    "Possible shortcomings of our analyis method / model:  \n",
    "\n",
    "- linear model: maybe yields predictions < 0 (--> we assume that this is not an issue for our \"region of interest\" (i.e., from -5°C to 25°C))\n",
    "- Normal distribution? --> maybe yields predictions that are not integers.\n",
    "- Poisson for count data would be good. But: Assumption is violated: Mean $\\neq$ Variance\n",
    "\n",
    "To think about:  \n",
    "Sind unsere Datenpunkte unabhängig voneinander? Wenn ich Fahrrad schonmal in Keller gebracht habe (für Winter), hole ich es vielleicht auch nicht mehr raus, auch wenn es nochmal wärmer werden sollte..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_literacy_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1e8da7b5fe6809889dc55a1e6b808245dc6c6da78d207026ed59616128f70ae3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
